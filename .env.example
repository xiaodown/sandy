######################################
# Example environment variables file #
######################################


# Discord API key
DISCORD_API_KEY="api_key_here_abc123"

# This is the database that keeps track of "seen" users
# and their server-specific nicknames, and is foreign
# key'd on the server_id.
# It also contains channel name / ID map and 
# server name / ID map, so it can avoid calling the discord
# api (and getting a bunch of 429's)
DB_DIR="data/"
SERVER_DB_NAME="server.db"

# Where the bot should look for the recall API
# Update these if recall is ever running on a different machine
RECALL_HOST=127.0.0.1
RECALL_PORT=8000

# Models
#BRAIN_MODEL="qwen2.5:14b"
#BOUNCER_MODEL="qwen2.5:14b"
BRAIN_MODEL="mistral-small"
BOUNCER_MODEL="mistral-small"
TAGGER_MODEL="hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0"
SUMMARIZER_MODEL="hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q8_0"

# How long ollama keeps models loaded in VRAM after the last request.
# Default is 5m
OLLAMA_KEEP_ALIVE=1h
    
#SUMMARIZE_THRESHOLD=144
SUMMARIZE_THRESHOLD=450

# Brain generation options
# Temperature: 1.0 = neutral, higher = more creative/weird. Start at 1.1, tune from there.
BRAIN_TEMPERATURE=1.0
# Max tokens per response. Discord hard limit is ~2000 chars; keep Sandy concise.
BRAIN_NUM_PREDICT=512
# Context window. Ollama defaults to 2048 regardless of model capability â€” set explicitly.
# 16384 costs ~1.8GB KV cache on 24GB VRAM (fine with 11GB headroom after model load).
# Gives room for RAG recall results without reconfiguring. Bump to 32768 if needed.
BRAIN_NUM_CTX=16384
